# ğŸ“„ GenAI Document Assistant â€” Data Science Internship Assessment

A full-stack **GenAI-powered assistant** that understands documents. Upload any `.PDF` or `.TXT` file, and the system can:

- ğŸ“ Summarize the content  
- â“ Answer your questions  
- ğŸš€ Automatically generate practice questions  
- ğŸ“Š Evaluate your answer and provide intelligent feedback

Built using **LangChain**, **Flan-T5**, **Django**, and **Streamlit**.

---

## ğŸ§  Features

| Feature              | Description                                         |
|----------------------|-----------------------------------------------------|
| ğŸ“¤ Upload Document   | Upload `.pdf` or `.txt` files                       |
| ğŸ“ Summary           | Generate a short, meaningful summary                |
| â“ Ask a Question     | Ask anything from the uploaded document             |
| ğŸš€ Challenge Mode     | Auto-generate a practice question from content      |
| ğŸ“Š Feedback          | Submit answers and get performance feedback         |
---

## ğŸ›  Tech Stack

| Layer       | Tools                                           |
|-------------|-------------------------------------------------|
| âš™ï¸ Backend   | Django, Django REST Framework, LangChain        |
| ğŸ§  LLM       | Flan-T5 (`text2text-generation` via HuggingFace)|
| ğŸ” Search    | FAISS vector store + Sentence Embeddings        |
| ğŸ“¤ Frontend  | Streamlit                                       |
| ğŸ“š NLP Utils | PyMuPDF (PDF parsing), spaCy, NLTK, Transformers|

---

## ğŸ“ Project Structure

-genai_project/
- â”‚
- â”œâ”€â”€ assistant/ # Django app (API layer)
- â”‚ â”œâ”€â”€ views.py
- â”‚ â”œâ”€â”€ urls.py
- â”‚ â””â”€â”€ models.py
- â”‚
- â”œâ”€â”€ backend/ # Core LangChain + QA/Summarizer logic
- â”‚ â”œâ”€â”€ qa_engine.py # Custom heading-aware QA logic
- â”‚ â”œâ”€â”€ summarizer.py # Custom summarizer with heading-aware rules
- â”‚ â”œâ”€â”€ challenge.py # Auto-question generator logic
- â”‚
- â”œâ”€â”€ genai_project/ # Django settings and routing
- â”‚ â”œâ”€â”€ settings.py
- â”‚ â”œâ”€â”€ urls.py
- â”‚ â””â”€â”€ ...
- â”‚
- â”œâ”€â”€ app.py # Streamlit frontend
- â”œâ”€â”€ temp/ # Stores uploaded files (optional)
- â”œâ”€â”€ requirements.txt
- â””â”€â”€ README.md

---

## ğŸš€ How to Run Locally

### 1. Clone the Repository

```bash
git clone https://github.com/your-username/genai-doc-assistant.git
cd genai-doc-assistant
```
### 2.Create a Virtual Environment and Install Dependencies
```bash
python -m venv .venv
source .venv/bin/activate        # On Windows: .venv\Scripts\activate
pip install -r requirements.txt
```
### 3.Run the Django Backend
```bash
cd genai_project
python manage.py migrate
python manage.py runserver
```
### 4.Run the Streamlit Frontend
Open a new terminal in the root project folder and run:
```bash
streamlit run app.py
```
---

## âš ï¸ Known Limitations

While the GenAI Document Assistant performs well on structured documents, it still has a few areas for improvement:

- ğŸ”„ **Answer Evaluation:** The feedback logic for long or descriptive answers may not always align with human reasoning, especially on subjective content.
- ğŸ§  **Challenge Question Depth:** Currently, challenge-mode questions are basic and rely on surface-level sentence structure.
- ğŸ“„ **Model Behavior:** The Flan-T5 model sometimes generates repetitive answers or hallucinations, especially when context is insufficient.
- ğŸ§ª **Offline Accuracy:** Offline QA logic (lemmatization, POS tagging) may miss some multi-word or embedded concepts in technical docs.

These limitations are being tracked for improvement via better prompt engineering, offline chunk filtering, and experimenting with different LLMs or hybrid retrieval pipelines.

---
